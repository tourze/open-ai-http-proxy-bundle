明白了，我将为你撰写一份完整的产品需求文档（PRD），用于实现 `open-ai-http-proxy-bundle`，具备 key 池管理、请求分发、模型映射规则、兼容多种 OpenAI API 实现，并提供 EasyAdmin 后台支持和安全控制。完成后我会尽快告知你。


# open-ai-http-proxy-bundle 产品需求文档

## 背景

随着大语言模型（LLM）的应用不断扩大，许多项目需要对接多个不同厂商的模型服务（如 OpenAI 官方接口、Azure OpenAI 服务、OpenRouter 聚合服务等）。每个服务提供商的 API 接口格式各异，如果直接在应用中适配多个接口，不仅增加开发复杂度，还导致切换模型或供应商时需要修改代码。理想的方案是提供一个**统一的 API 接口**：应用只需对接这一接口，即可灵活调用不同后端模型服务。同时，OpenAI 官方对每个 API key 存在调用频率和配额限制，单一 key 难以满足高并发请求需求。通过引入一个代理层，可以**聚合管理多个 API Key**，实现负载均衡和故障转移，提高稳定性。此外，代理层还能提供**日志记录、监控、访问控制**等增强功能。基于以上背景，我们提出开发 Symfony Bundle —— **open-ai-http-proxy-bundle**，用于在 Symfony 项目中快速集成一个 OpenAI API 协议兼容的代理服务。

## 目标

open-ai-http-proxy-bundle 的开发目标包括：

* **统一接口调用**：对外暴露与 OpenAI API 格式兼容的 HTTP 接口，应用只需调用代理接口即可访问不同厂商的模型服务，无需关心底层差异。
* **多 Key 管理与负载均衡**：支持配置多个 OpenAI或兼容 API 的密钥（API Key），通过灵活的调度策略（轮询、随机、权重、负载等）分发请求，突破单一 Key 的限制，提高服务可用性。
* **模型灵活映射**：提供模型名称映射规则，支持根据自定义策略将用户请求的模型名替换为实际调用的模型名，实现如模型降级、供应商特定名称适配等功能。
* **可视化配置管理**：所有密钥配置和模型映射规则存储在数据库中，并集成 EasyAdminBundle 提供后台管理界面，方便运营人员添加/更新配置。
* **厂商协议兼容**：兼容不同厂商的 OpenAI风格接口（如OpenAI官方、Azure OpenAI、OpenRouter等），通过配置对应的 Endpoint URL 和 Key 实现请求转发。
* **安全与权限控制**：实现代理层自身的访问鉴权机制，提供内部\*\*访问令牌（token）\*\*的管理体系。调用方须携带合法的内部 token 才能访问代理接口，从而控制外部访问权限。避免直接暴露后端真实API Key，提高安全性。
* **限流与监控**：支持对请求频率进行限制，防止滥用；记录请求日志，便于日后分析使用情况和排查问题。

## 功能概述

open-ai-http-proxy-bundle 将提供以下主要功能：

* **多API Key管理**：支持配置多个 OpenAI 或兼容服务的 API Key。每个 Key 配置项包含：API Base Endpoint、密钥值、支持的模型列表、来源类型（如 OpenAI 官方、Azure、OpenRouter 等）、启用/禁用状态等。
* **统一HTTP代理接口**：Bundle注册一组与 OpenAI API路由兼容的 HTTP 接口（例如 `/proxy/v1/chat/completions`、`/proxy/v1/completions` 等），接收来自应用的请求后，按照调度策略选择后端实际的 API Key 和服务，将请求转发并返回结果。代理接口在参数和响应格式上与官方 OpenAI API 保持一致，支持流式输出等特性，方便直接替换。
* **调度策略**：内置多种后端 Key 选择策略，包括顺序轮询、随机分配、权重轮询（根据每个Key的权重比例）、按负载优先（根据当前请求量或剩余配额选择最空闲的Key）等。可配置默认策略，支持针对不同模型或不同调用场景指定策略。
* **模型名称映射**：提供模型映射规则配置。当用户请求使用某模型时，代理可根据预设规则替换为实际调用的模型名。例如用户请求`gpt-4`，可根据策略映射为`gpt-3.5-turbo`或 Azure 部署名等。支持通配符映射，用于未明确列出的模型默认映射关系。
* **多厂商兼容**：针对OpenAI官方、Azure OpenAI、以及其他遵循OpenAI接口协议的服务（如部分本地部署模型或第三方代理），通过配置不同的API Base URL、API Key和必要参数即可支持。Bundle在转发请求时，会根据不同来源类型对请求做适配：例如，Azure OpenAI需要在请求路径或Header中包含部署名称和 API版本参数，Bundle 会从配置中获取这些信息并正确构造请求。
* **多接口支持**：代理支持 OpenAI 所有主要接口的转发，包括聊天补全（Chat Completions）、文本补全（Completions）、Embedding 向量生成（Embeddings）、内容审核（Moderations）等常用接口，以及将来 OpenAI 新增的接口。只要后端服务支持相应功能，代理即可无缝转发。
* **内部 Token 鉴权**：代理服务提供一套内部访问令牌管理机制。管理员可在系统中生成、注销令牌，并分发给应用使用。应用在调用代理接口时需在HTTP Header中提供 `Authorization: Bearer <内部token>`。代理收到请求后先校验内部token有效性，再继续处理转发。通过这种方式，可以将真实的OpenAI API Key隐藏在代理后端，客户端只需使用内部token即可访问相应服务，提高安全性。内部token可以附加权限范围（例如限定可使用哪些模型或每日请求次数等），确保更精细的访问控制。
* **请求日志与监控**：系统会记录每次代理请求的关键信息，如时间、调用方（内部token）、请求模型、使用的后端Key、请求耗时、返回状态、消耗的token数量（如果可获取）等。日志存储在数据库（或可选外部日志系统）中。提供基础的日志查询界面，便于管理员监控使用情况。未来可扩展统计报表，用于分析各Key使用频率、失败率等。
* **限流策略**：支持针对内部token或整体代理服务设置调用频率限制。例如每个token每分钟最多请求数、全局每秒并发限制等。一旦超过阈值，代理接口应返回适当的错误码（如429 Too Many Requests）并拒绝服务，以保护后端资源不被滥用。限流配置可在后台调整。
* **错误处理及回退**：当某个后端服务请求失败（如网络错误、超时、配额用尽等），代理可以根据策略进行失败处理。基本行为是返回相应错误给调用方，但未来可扩展为**故障自动切换**：例如在顺序轮询策略下，一个Key失败时自动尝试下一个Key，或者根据错误类型动态降级模型（例如请求GPT-4失败时自动改用GPT-3.5）等，提升整体服务可靠性。

## 详细功能模块说明

### 1. API Key 管理模块

**功能描述**：提供对多个 OpenAI/兼容 API Key 的集中管理。管理员可以在后台添加、编辑、启用/禁用各个Key配置。每条 Key 配置应包含以下字段：

* **名称/标识**：用于区别不同Key的自定义名称。
* **来源类型**：枚举值，如 OpenAI、Azure、OpenRouter、本地等，用于指示该Key对应的服务提供商类型。
* **API Base Endpoint**：该Key对应服务的基础 URL。例如：

    * OpenAI 官方：`https://api.openai.com/v1`
    * Azure OpenAI：`https://<你的资源名>.openai.azure.com/openai/deployments/<部署名>` （可能不同接口，会在配置中细化）
    * OpenRouter：`https://openrouter.ai/api/v1`
    * 其他自托管服务：填写其公开的兼容接口地址。
* **API Key Value**：密钥的值本身。例如以“sk-...”开头的 OpenAI Key，或 Azure 提供的密钥字符串。该字段应安全存储，可考虑数据库加密或至少在界面上遮挡显示。
* **支持模型列表**：可选配置，列出该Key支持的模型名称（或模式）。用于代理在调度时判断某个请求的模型是否可由此Key处理。如果留空则默认视为支持所有模型（除非由来源类型限制）。
* **权重**：用于加权轮询策略的权重值，默认为1。权重越高，在负载均衡时获得请求的概率越大。
* **状态**：启用或禁用。禁用状态的Key在调度时将被跳过，不会被选用。方便临时下线某个Key进行维护或排除故障。

**工作流程**：当管理员添加一个新的 API Key 配置后，系统会验证基本可用性（例如尝试调用该Key获取模型列表或一个简单请求），确保配置有效。Key信息存储于数据库的 `api_keys` 表，并与模型映射等模块关联。在请求调度过程中，系统根据调度策略从已启用状态的 Key 列表中选择合适的 Key 来转发请求。

**示例**：管理员配置两个 OpenAI Key（KeyA和KeyB）和一个 Azure Key (KeyC) 并都启用。其中KeyA、KeyB来源类型为OpenAI，共支持`gpt-3.5-turbo`和`gpt-4`，KeyC来源类型为Azure，只支持部署了`gpt-35-turbo`的模型。用户请求一个模型`gpt-4`的聊天补全时，调度模块会在KeyA和KeyB中选择（因KeyC不支持gpt-4）。若采用轮询策略则交替使用KeyA/KeyB。

### 2. HTTP Proxy 接口模块

**功能描述**：Bundle将注册一系列HTTP路由，充当OpenAI API的代理入口。这些路由与OpenAI官方接口路径尽量保持一致，仅在前缀上有所区别。例如：

* `POST /proxy/v1/chat/completions` 对应 OpenAI 的 Chat Completions 接口。
* `POST /proxy/v1/completions` 对应文本补全接口。
* `POST /proxy/v1/embeddings` 对应 Embeddings 接口。
* `POST /proxy/v1/moderations` 对应 Moderation 接口。
* 以及其它可能的接口路径（如 `/images/generations` 图像生成、`/audio/transcriptions` 语音转写等），可根据需要扩展支持。

所有代理接口接受与官方API相同的请求格式和参数，并返回相同格式的响应，因而对调用方来说是透明的（完全兼容 OpenAI SDK 等调用方式）。代理接口需要处理**流式响应**（Server-Sent Events）：当请求包含 `stream=true` 参数时，代理会打开HTTP流，将后端的逐步生成结果实时转发给客户端，保证行为与OpenAI一致。

**工作流程**：

1. **请求接收**：客户端向 `/proxy/v1/...` 路径发起HTTP请求（POST为主，GET用于少数查询接口）。请求Header中需包含 `Authorization: Bearer <内部token>` 以及必要的 `Content-Type: application/json` 等。Bundle的路由控制器拦截请求后，首先进行**内部token鉴权**（详见“安全控制”部分）。鉴权通过后，进入下一步。

2. **参数解析**：代理读取请求的JSON Body，提取关键字段如 `model`（模型名称）、请求体内容等。根据 `model` 值和配置的模型映射规则，可能对模型名进行替换（如果匹配某条映射规则）。例如请求指定 `gpt-4`，而配置了映射为 `gpt-3.5-turbo`，则实际请求会改用后者模型。

3. **选择后端 Key**：调用调度模块，根据选定的调度策略挑选一个可用的 API Key 配置。输入参数包括：请求的模型名称（映射后）、各Key支持模型列表及当前可用状态，以及各Key的权重、近期负载指标等。调度模块返回最终选中的 Key（例如 KeyB）。

4. **构造后端请求**：根据选中的 Key 配置，构造对应厂商所需的 HTTP 请求：

    * 确定目标 URL：将代理路径替换为该Key的 Base Endpoint。例如，若KeyB Base Endpoint为 `https://api.openai.com/v1`，且当前请求路径为 `/proxy/v1/chat/completions`，则目标URL为 `https://api.openai.com/v1/chat/completions`。对于Azure等需要特殊路径的，则按照其Endpoint模板插入部署名等。
    * 设置认证信息：将请求头中的 Authorization 换成目标服务需要的认证方式。常见情况是使用 Bearer Token，将内部token换为实际的 API Key 值。但对Azure OpenAI，认证仍是api-key header或key放入请求头的 `api-key` 字段。Bundle需根据 Key 类型处理，例如：

        * OpenAI/OpenRouter：请求头 `Authorization: Bearer <Key值>`。
        * Azure：请求头 `api-key: <Key值>`，并确保 URL 包含 `api-version` 查询参数，路径包含 deployment 名称。
    * 转发请求体：将之前解析/可能修改后的 JSON 直接作为请求主体发往目标服务。确保 Content-Type 等头正确。
    * 其他必要调整：如User-Agent设置、超时设置（可使用 Symfony HttpClient 设置合理的超时时间）。

5. **响应处理**：收到后端服务的响应后，Bundle直接将响应内容返回给调用客户端。通常无需修改响应JSON，以保持与OpenAI格式一致。但在某些厂商返回格式略有差异时（例如Azure的部分字段不同），需要在兼容协议为“openai”模式下对响应进行适配转换为OpenAI格式。流式响应情况下，代理逐行读取后端流并立即向前转发。

6. **错误处理**：如果后端请求发生错误（网络超时、HTTP错误码非200等），代理应捕获异常，按照OpenAI错误格式生成对应的错误响应返回客户端。同时记录该错误事件，以便后续分析。如果是由于选定Key的问题导致（如配额耗尽），可结合策略进行重试或切换Key（基础版本中可不实现自动重试，作为扩展功能）。

**性能考虑**：代理接口应该高效非阻塞地转发数据。例如利用 Symfony HttpClient 的异步/流式处理能力确保低延迟。同时，Bundle应支持配置**并发连接数**和**超时时间**等参数，确保在高并发场景下稳定运行。

### 3. 调度与负载均衡模块

**功能描述**：根据预定义的策略，从可用的后端 Key 列表中选择一个来处理当前请求。良好的调度策略可以平衡各Key的使用率，避免单点瓶颈，并在某些Key失效时自动切换。

支持的调度策略包括：

* **顺序轮询（Round Robin）**：按照预先定义的顺序循环选择Key。每次请求使用上次之后的下一个可用Key，依序循环。这是默认的简单负载均衡策略，可确保多Key情况下请求分布均匀。
* **随机（Random）**：每次请求随机挑选一个可用Key。适用于Key性能和配额相近的情况，简单且具一定均衡效果。
* **加权轮询（Weighted Round Robin）**：每个Key配置一个权重值。调度时按照权重比例分配请求频率。例如KeyA权重2、KeyB权重1，则大约2/3请求给A，1/3给B。适合不同Key的性能或额度差异较大时使用。
* **按负载（Least Load）**：实时评估各Key当前负载或剩余额度，选择最“空闲”或“资源充足”的Key。例如根据过去一分钟内请求数、OpenAI剩余速率限额等指标，动态挑选最优Key。这需要Bundle维护每个Key的简单使用统计。
* **故障剔除**：不算独立策略，但调度模块应能检测到某些Key近期连续出错，暂时停止分配请求给它（熔断机制），提高成功率。

管理员可以在配置中全局设置默认的调度策略，以及为特定模型或来源类型指定专用策略（例如对耗费特别高的`gpt-4`模型，可以设置更谨慎的轮询规则）。调度模块的实现需考虑线程安全，在高并发下正确更新和读取轮询状态。

**示例**：假设有3个Key（A、B、C），选择加权轮询策略，权重分别为5、3、2，则预期每10次请求大致分配：5次A、3次B、2次C。如果B出现多次超时错误，系统自动将B标记为暂时不可用并告警，此时只在A和C之间调度，待管理员修复B或错误率下降后再恢复。

### 4. 模型映射配置模块

**功能描述**：允许管理员定义模型名称映射规则，实现请求模型到实际模型的替换。这一功能的作用包括：

* **模型别名**：有时不同供应商对于同样能力的模型名称不同，映射可以让用户使用统一名称。例如用户请求`gpt-3.5-turbo`，但Azure上的部署模型名称可能需要写为`gpt-35-turbo`或自定义的部署ID。通过映射，代理能将`gpt-3.5-turbo`转换为Azure对应名称再请求。
* **模型降级/升级**：在资源紧张或策略需要时，将高阶模型请求转为低阶模型执行。如将`gpt-4`映射为`gpt-3.5-turbo`处理，以降低成本或提高响应速度。
* **自定义路由**：某些特殊模型请求可路由到不同后端。例如定义规则：“当请求模型为`claude-v1`时，实际调用Anthropic的Claude API接口”。虽然Anthropic接口与OpenAI不完全相同，但如果通过OpenRouter等兼容渠道，也可以通过映射实现（此场景复杂，需在兼容性部分处理）。

**配置方式**：模型映射规则存储于数据库中的 `model_mappings` 表。每条规则包含：`源模型名` -> `目标模型名`，以及可选的条件如限定某个来源类型或限定使用某组Key等。还可设定一条通配符规则（源模型名为"\*"），作为默认fallback映射，用于没有其他匹配规则时适用。如果不配置映射，则默认请求模型名原样传递给后端。

**映射应用时机**：在代理接口接收到请求并解析参数后、选择具体Key之前，就应进行模型名映射。这样保证调度决策用的是映射后的真实模型名（特别在Azure这种每个模型单独部署的情况下，需要知道部署名才能选对Key）。对于同一请求，不会应用多次映射（防止循环映射）。

**示例**：配置规则：

* `源: "gpt-4" -> 目标: "gpt-3.5-turbo"`（不限定来源，通用规则）。这意味着所有请求gpt-4都会改为gpt-3.5-turbo执行，返回结果也仍标示gpt-3.5内容（或代理可在结果中替换模型字段以假装是gpt-4，如有需要）。
* `源: "gpt-4" (Azure 类型) -> 目标: "gpt4-deployment-xyz"`（限定Azure来源）。当使用Azure的Key时，如果请求模型是gpt-4，则替换为部署名“gpt4-deployment-xyz”再拼接请求URL。
* `源: "*" (OpenRouter 类型) -> 目标 保持不变`。例如OpenRouter本身支持很多模型且使用`provider/model`格式，可能无需修改模型名，通过此默认映射表示对OpenRouter请求不做改动。

模型映射提高了代理的灵活性，使运营者能根据策略调整后端调用而不需要客户端修改请求。

### 5. 安全控制与鉴权模块

**功能描述**：确保只有授权的应用和用户才能使用代理服务，并防止敏感信息泄露。主要包括**内部Token鉴权**和**密钥安全存储**两部分。

* **内部 Token 鉴权**：如前述，代理使用内部发行的访问令牌来控制调用权限。管理员可以在“令牌管理”界面生成新token，指定token名称、用途说明、有效期（可选）、权限范围等。生成后系统返回一个token串（格式可参考OpenAI Key风格，如`oa-proxy-xxx`或自定义前缀），此token只显示一次需妥善保存。客户端调用代理时，在HTTP请求头加入 `Authorization: Bearer <token>` 来认证。代理收到请求先验证：

    * Token是否存在、有效、未过期；
    * Token是否有调用对应接口或模型的权限（如配置了黑/白名单）；
    * Token的调用频率是否在允许范围（可与限流模块结合，实现每个token独立的速率限制和配额控制）。

  若验证失败，返回HTTP 401或403错误。不通过鉴权的请求不会进入后续实际转发流程。

  **内部Token的优势**在于可以避免直接将OpenAI等后端Key暴露给前端应用或第三方。即使前端token泄露，也可在代理侧单独吊销，不影响后端Key安全。同时可以针对不同应用发放不同token，实现隔离和精准控制。

* **密钥安全存储**：代理后台所配置的各后端API Key属于敏感信息。在设计上需确保：

    * **传输安全**：管理员在后台填写Key时，应通过HTTPS访问管理界面，防止明文截获。
    * **存储安全**：数据库中存放Key可以考虑加密存储（例如对称加密密钥由环境变量提供）。即使数据库泄露，也无法直接获得明文Key。至少在UI展示上，Key应做掩码处理，非必要不显示全量。
    * **日志安全**：在请求日志中避免记录完整的后端Key，可以记录Key别名或ID以供内部分析。如需调试细节，也应有配置开关控制日志中是否包含敏感信息。

* **权限分离**：后台管理操作（添加Key、生成token等）应需要管理员权限，普通用户不能获取或修改这些配置。可考虑引入Symfony自带的安全组件，设定防火墙和角色。令牌管理界面可能仅管理员可见。

* **CORS与访问控制**：由于代理接口可能被浏览器前端直接调用，需要配置适当的 CORS（跨域资源共享）策略。可允许信任的域访问，防止任意第三方网站用AJAX盗用代理服务。Bundle应提供配置项设定允许的Origin列表。

* **IP访问限制**（可选扩展）：类似 openai-forward 工具所支持的 IP 白名单/黑名单机制。管理员可配置只有来源IP在白名单的请求才处理，或屏蔽某些恶意IP。该功能在后续版本实现。

**示例**：某公司内部两个应用App1和App2都需要调用ChatGPT服务。管理员为它们各生成一个token（TokenA, TokenB），并分别授予不同权限（例如TokenA允许调用gpt-4，TokenB只能用gpt-3.5）。App1和App2在调用代理时各自使用各自的token。代理通过token识别调用方并校验权限，确保App2即使请求gpt-4也会被拒绝或自动转为gpt-3.5执行（结合模型映射实现）。如果某token泄露或不再需要，可以在后台禁用或删除，该token随即失效，不影响其他token及后端Key。

### 6. 日志记录与请求监控模块

**功能描述**：对代理服务的请求进行日志记录和统计分析。

* **日志内容**：每次请求至少记录：

    * 时间戳、请求方标识（可记录内部token的ID或调用者IP等）、
    * 请求路径和方法（如`POST /v1/chat/completions`）、
    * 请求的模型名、关键参数（如是否使用stream模式、max\_tokens等）、
    * 选择的后端Key标识（例如Key名称）、
    * 后端响应时间、返回状态码，若有错误则记录错误类型。
    * （可选）消耗的token数量及费用估算。OpenAI响应会包含usage字段，代理可提取这部分记录以供统计费用。

* **日志存储**：可采用关系型数据库的独立日志表（如 `request_logs`），字段包括上述信息。对于流式长连接的请求，可以记录开始和结束分别一条日志或者在结束后更新日志信息。日志表可能增长迅速，需做好归档或清理策略，或可选写入文件/外部日志系统。

* **监控界面**：在管理后台提供基础的日志查看功能。支持按时间、token、模型、Key等过滤检索请求记录。这样管理员能了解各应用的使用情况及后端Key健康状况。例如，可以查询过去24小时每个Key的调用次数和成功率。**Dashboard**：未来可扩展一个仪表盘，直观展示请求数曲线、错误率、不同模型占比等指标，辅助运营决策。

* **告警**（扩展）：支持设定告警策略，如连续失败超过一定阈值，或某Key余额/次数达到阈值时，发送通知（邮件或系统消息）给管理员。这部分可对接Symfony通知组件或独立实现。

**示例**：管理员通过日志界面发现，某段时间KeyA的错误率飙升，响应变慢，由此判断该Key可能达到OpenAI限流或发生故障。于是临时在Key管理中将KeyA禁用，同时切换调度策略避免继续使用它，保障服务稳定。日志的统计也显示过去一周80%的请求都是对`gpt-3.5-turbo`模型，而`gpt-4`只占20%，据此可以评估成本和调整策略。

### 7. 后台管理模块

**功能描述**：通过 Symfony EasyAdminBundle 提供一个直观的后台管理界面，方便非开发人员进行配置和运维。主要子模块和界面包括：

* **API Key 配置管理界面**：显示所有已配置的后端 API Key 列表，每项展示名称、类型、Endpoint简要、启用状态、权重等。提供“新增Key”按钮，点击进入表单填写上述Key字段。列表项支持编辑和删除操作（考虑到引用关系，删除需谨慎，例如只能删除禁用状态且无请求使用记录的Key）。启用/禁用可以作为快捷开关直接在列表页操作。页面还可显示每个Key近期的统计（如累计调用次数、错误率等）供参考。

* **模型映射规则管理界面**：列出所有映射规则，展示源模型、目标模型、限定条件等。支持新增/编辑/删除规则。新增规则表单包括：源模型名（文本，支持通配符或正则匹配，可选下拉常用模型名）、目标模型名（文本，下拉选已知模型或自由填写）、适用Key类型/ID（可不填表示全局规则，或选定特定来源Key应用）、备注说明等。规则列表按优先级排序（精确匹配优先于通用规则），并在规则冲突时给予提示（防止出现两个规则条件相同时映射不同结果的冲突）。

* **访问令牌管理界面**：提供内部token的管理。列表显示token标识（可用描述性名称或前几位字符）、创建者、创建时间、是否有效、权限说明、最近使用时间等。新增token时，后台生成随机字符串作为token值，并可设置：

    * 关联的应用或用户（可选，仅作为备注区分用途）、
    * 权限（如可调用的模型范围、每分钟调用上限、总配额等。如果初期不做细粒度控制，可忽略或只设全局默认策略）、
    * 有效期（无限制或设置到期时间）、
    * 状态（启用/停用）。

  为安全起见，token值只在创建时显示一次，之后只显示部分遮掩。如需重置则生成新token。支持单个token的禁用（即临时吊销权限）。

* **日志查看界面**：提供近期请求日志列表，可分页浏览。字段较多，可让管理员自定义显示列。如按时间倒序显示时间、token、接口、模型、Key、耗时、状态、错误信息等。支持筛选（顶部有按日期范围、token、接口路径、状态等过滤选项）。如果需要深入分析，日志界面也可支持导出功能，把筛选结果导出为CSV供外部分析。

* **系统设置界面**（可选）：用于配置全局参数，如默认调度策略、全局并发上限、CORS允许来源列表、日志保留天数等。也可以包括是否开启某些扩展功能的开关（如IP白名单校验开关等）。

**UI/UX**：管理界面应尽量简洁明了。通过菜单区分不同管理功能模块（Key、映射、令牌、日志、设置等）。各表单提供字段校验，避免输入错误数据（例如Endpoint URL格式校验、模型名不能为空等）。考虑国际化需求，界面文本支持中英文。

**权限**：后台管理界面应受权限保护。仅授予具有ADMIN角色的用户访问。可利用Symfony Security组件配置路由的访问控制，或在EasyAdmin配置中限定角色。

**示例**：运营人员登录后台后，进入“渠道 (API Key) 管理”菜单，看到当前配置了5个渠道，包括2个OpenAI官方Key、1个Azure Key、1个OpenRouter Key、1个本地模型代理Key。发现其中一个OpenAI Key快到期了（在备注中标明有效期），于是新增了一个新的OpenAI Key配置，并将旧Key状态置为停用。接着进入“令牌管理”，为新接入的应用生成了一个访问令牌，限制其每天最多调用1万次。随后查看“日志”，确认最近的请求都正常通过新Key，没有出现错误。

## API 列表

open-ai-http-proxy-bundle 对外提供的主要HTTP API包括以下几类（均遵循 OpenAI v1 版本的路径格式）：

1. **Chat Completions 聊天补全** – `POST /proxy/v1/chat/completions`
   与OpenAI的ChatGPT接口兼容。请求JSON需包含 `model`, `messages` 列表等参数，支持流式返回选项。典型返回字段包括 `id`, `object`, `created`, `choices`, `usage` 等。

2. **Completions 文本补全** – `POST /proxy/v1/completions`
   对应OpenAI文本补全（如 davinci 等模型）的接口。请求包含 `model`, `prompt` 等，返回 `choices` 列表及 `text`结果。

3. **Embeddings 向量嵌入** – `POST /proxy/v1/embeddings`
   请求提供 `model` 和 `input`文本，返回 `data`数组，其中含每段输入的向量表示（embedding）。

4. **Moderations 内容审核** – `POST /proxy/v1/moderations`
   请求 `input`文本，代理调用内容审核模型（如 OpenAI Moderation），返回是否违规的分类结果。

5. **图像生成**（可选） – `POST /proxy/v1/images/generations`
   如果配置的后端支持 OpenAI 图像生成API，则代理可转发该接口，请求包含 `prompt`, `n`, `size` 等参数，返回生成的图像URL或base64数据。

6. **音频转录**（可选） – `POST /proxy/v1/audio/transcriptions` / `translations`
   代理转发音频识别请求，如 Whisper 模型的接口。请求包含音频文件，返回转录文本。

7. **模型列表查询** – `GET /proxy/v1/models`
   返回代理支持调用的模型列表。可由后端OpenAI接口提供，或由代理汇总配置的Key支持模型得出。如果后端为OpenRouter等聚合，也可能返回多个提供商模型。此接口帮助客户端了解可用模型名称。

以上所有 POST 请求接口均要求使用 `Authorization: Bearer <内部token>` 进行鉴权（除非针对模型列表查询等公开信息，可考虑免鉴权但也可以要求鉴权）。请求和响应体格式遵循 OpenAI 定义，不再赘述。代理不会新增自定义的业务字段，以确保兼容性。

此外，Bundle可能提供少量**管理类API**（可选），如通过REST API管理内部token或查看系统状态等。但由于已有后台界面和安全考虑，这些管理API通常仅供内部或未来扩展使用，默认不公开文档给普通调用者。

## 安全控制

本节汇总open-ai-http-proxy-bundle的安全机制：

* **访问鉴权**：所有对代理接口的调用必须通过内部token认证。未携带或认证失败的请求将被拒绝（HTTP 401 Unauthorized）。管理员应定期审查已发放的token，最小化权限范围，及时吊销不需要的token。

* **权限范围**：在发行内部token时，可配置其权限。例如限定只能使用某些模型、限定每日/每月最大调用次数、限定可访问的接口类型等。Bundle首版可只实现简单的“启用/禁用”和全局限流，细粒度权限控制作为扩展点。

* **流量限流**：通过Symfony RateLimiter组件或自定义实现，对代理请求进行限流。分为**应用级限流**和**全局限流**：

    * 应用级限流：以token或调用方为维度，如每个token每分钟不超过N次请求。超过则返回429错误。参数N可以全局统一设定，也可针对不同token配置。
    * 全局限流：代理总体的最大吞吐限制，如每秒处理请求不超过M次，或单IP每分钟不超过X次。防止单一恶意来源打爆服务。
    * 针对特定接口的限流：如图像生成接口成本高，可设更严格频率限制。

* **后台安全**：管理后台登录需要账号密码，建议集成Symfony Security的用户体系。默认仅内置一个超级管理员账号（首次安装后应修改默认密码）。支持管理员账号管理和审计（比如记录谁添加/修改了哪些配置）。考虑支持基于LDAP/SSO的企业登录集成作为未来扩展。

* **数据安全**：数据库中的敏感信息（API Key、Token等）做好加密或散列存储。只有Bundle内部掌握解密密钥。日志中尽量避免明文敏感数据。

* **通信安全**：代理服务应部署在HTTPS环境下，确保客户端与代理通信加密。特别是内部token在传输中应避免明文泄露。若代理进一步调用外部API，也应验证SSL证书、考虑超时和重试策略，避免因外部不稳定导致安全问题。

* **依赖安全**：关注Symfony及相关组件的安全更新，及时升级Bundle版本。因为该Bundle主要用于服务端，需定期检查依赖库的安全公告。

综上，安全控制贯穿密钥管理、调用鉴权、限流防滥用等方面，保障代理服务稳定、安全地运行。

## 后台管理

open-ai-http-proxy-bundle 将EasyAdmin作为后台界面的基础，实现**配置—监控—维护**的一站式管理。以下是后台主要功能模块的再整理：

* **渠道管理（API Keys）**：菜单项“渠道”列出所有配置的后端渠道(API Key)。管理员可以添加新渠道，或编辑现有渠道信息。典型操作如修改权重、启用禁用、删除无用Key等。列表也直观显示每个渠道的当前状态（比如一个红色图标表示已禁用或故障）。未来版本可在此页面显示渠道余额或调用统计，让管理员及时了解各Key使用情况。

* **模型映射**：菜单项“模型映射”进入模型名称映射规则列表。支持添加映射规则（源->目标），并配置适用范围。UI上可以在添加规则时提供当前系统已知模型的自动完成，以减少输入错误。映射规则的生效顺序（优先级）清晰展示，管理员可调整顺序或设置通配符默认规则。在调试阶段，最好也提供一个**测试功能**：让管理员输入某源模型名和指定渠道，快速查看映射后的结果，验证配置正确性。

* **令牌管理**：菜单项“访问令牌”管理所有内部API访问令牌。可创建新令牌，支持选择关联的应用或用户（文本描述）和权限设置。列表应支持按应用/用户筛选，方便查找某个调用方的token。为了安全，列表不显示完整token值，仅显示标识和元数据。支持一键复制token值（在创建成功后弹窗中）。管理员可随时禁用或删除某token。也可在界面上看到每个token的使用量统计（总请求次数、上次使用时间等），以判断是否活跃或滥用。

* **请求日志**：菜单项“请求日志”呈现日志记录查询界面。默认显示最近100条请求，可加载更多或分页。支持组合过滤，如按照日期范围+特定token+状态码筛选。日志详情支持展开查看完整请求和响应（可用于调试，但需注意敏感信息）。该界面主要供运维排查问题、了解系统运行状况。

* **系统设置**：可选菜单“系统设置”集中配置一些全局参数。比如：

    * 调度策略默认值选择（下拉：轮询/随机/权重/按负载）。
    * 全局速率限制阈值配置。
    * CORS允许来源列表编辑。
    * 日志保留天数设置，超过则自动清理。
    * …等等可能需要管理员调整的参数。

  这些设置变更后通常需要重启或即时生效，应在UI上给予说明。

**技术实现**：利用 EasyAdminBundle，可以为每个实体（Key实体、Mapping实体、Token实体、Log实体等）配置CRUD界面，以及定制列表展示和表单字段。部分非简单CRUD的功能（如日志筛选、测试映射等）可能需要自定义Controller或利用EasyAdmin的自定义Action机制实现。权限方面，通过Security配置保证只有ROLE\_ADMIN用户可以访问这些后台路由。UI风格与Symfony后台统一，力求简洁可靠。

**用户体验**：考虑到用户主要是开发者或运维人员，界面注重信息完整和操作安全。例如删除操作需要确认，修改关键配置需提示重启服务或立即应用。对新手可提供简短的帮助提示，例如在模型映射页面说明如何书写通配符。

## 未来扩展点

在基本功能实现基础上，open-ai-http-proxy-bundle 未来可以考虑以下扩展和改进：

1. **更多模型供应商集成**：目前支持的供应商以OpenAI接口兼容为主。未来可扩展适配其它知名模型API，例如 Anthropic Claude（其API格式不同，需要在代理层进行请求/响应转换）、Google PaLM/Gemini API 等。也可以支持国内模型如百度文心、一些开源大模型的API网关（许多国内服务已提供OpenAI兼容接口，可直接接入）。通过插件或配置驱动的方式，增加供应商类型的支持，使Bundle成为真正的“一站式LLM网关”。

2. **自动故障转移与智能调度**：增强调度模块，加入**健康监测**机制。定期检测各Key的可用性，例如调用一个轻量型接口验证。若某Key不健康，自动停止使用一段时间。实现**自动重试**：当使用某Key的请求失败时，可捕获特定错误（如429配额超限）后切换另一个Key重新请求一次，然后将结果返回并在日志中标记重试行为。这提升系统容错能力，但也要防范由此引起的连锁负载问题。未来甚至可引入AI模型路由策略，例如根据请求内容或长度，智能选取最经济的模型等（MoE思想）。

3. **更精细的统计和计费**：加入对每个内部token的用量统计和限制。如每个token每日消费的Prompt/Completion tokens数量，总计成本估算，以及设定每个token的额度上限（用完则暂停服务或通知）。这对于将来如果对外部用户开放服务、进行计费非常重要。可通过解析OpenAI响应中的usage字段累加统计，提供按token、按模型、按时间维度的汇总报表。

4. **缓存与加速**：对于某些请求结果（尤其是相同的Embedding生成等幂等请求），可考虑增加缓存功能，避免重复调用浪费资源。也可以在代理层针对相同用户会话的连续请求应用**上下文缓存**或**结果缓存**，提高响应速度（需要小心不同prompt不宜缓存的问题）。另外，支持HTTP层面的GZIP压缩传输，以节省带宽。

5. **请求修改管道**：提供扩展点让开发者对请求和响应进行自定义处理。例如在转发前对用户Prompt进行统一预处理（过滤敏感词，加入上下文等），或在返回结果前插入水印信息等。这可通过Symfony的Event机制，允许注册监听在请求发送前/后执行自定义逻辑。

6. **更友好的开发者支持**：撰写完善的开发文档和使用指南，提供示例代码。也可以考虑将代理本身的OpenAPI (Swagger) 文档生成，方便调试。对于使用Bundle的开发者，提供可配置选项的文档，说明如何在Symfony项目中引入及配置本Bundle。

7. **横向扩展与集群支持**：当请求量极大时，需部署多实例负载均衡。Bundle未来可支持使用共享数据库/缓存，使多实例共享配置信息和请求计数。例如引入Redis缓存来协同限流计数。确保无状态或恰当的session处理，以便通过Kubernetes等横向扩容代理服务。

8. **支持Websocket/长连接**：如果未来OpenAI接口升级使用Websocket等通信方式，代理需相应支持升级。目前的流式通过HTTP流已经满足大部分需求。

9. **兼容旧版OpenAI API**：视需要支持 OpenAI 的v1以外版本或特殊用途API（如Fine-tunes微调、文件上传等）。这些并非核心聊天功能，但若用户有需求可加入。

10. **插件化设计**：将某些功能设计为可插拔模块，如不同供应商适配器、调度策略算法、日志存储后端等。这样方便根据不同项目需求裁剪功能，或由社区贡献新策略和支持更多厂商。

通过以上扩展，open-ai-http-proxy-bundle 将不断完善，适应日新月异的AI接口生态，帮助开发者以最小代价集成和管理多模型、多Key的调用，打造高可用、高扩展性的 AI 应用服务层。〖完〗

**参考资料：**

* 骑鱼猫, *“如何同时接入多个AI大模型？LLM代理/LLM网关的应用”*, 博客园 (2024)
* songquanpeng, *One API 项目简介*, GitHub
* kunyuan, *openai-forward 项目介绍*, PyPI
* Alibaba Cloud, *“AI 代理 - 基于OpenAI契约的代理功能”*, Higress 文档
* Josh Kasuboski, *“One API to Rule Them All: Building an OpenAI Gateway”*, Personal Blog (2025)
